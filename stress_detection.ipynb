{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxkotur/ml-stress-detection/blob/main/stress_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ychCE32xmz",
        "outputId": "af882c94-8d80-4126-ef58-739d7b2f0208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 25 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.64.1)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30534 sha256=5546579c7025b337a234735566671b42de8a16afb9a563e749668706eff66a89\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/a4/72/df07592cea3ae06b5e846f5e52262f8b16748e829ca354b7df\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=1af79fd33ef7f98958dd9aad0b567cefb2595167182b71a90a8c066da50e6ac0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f3/85/b8cf1d8bfe55dc2ece0f1fcd4e91d6f8fc7b59ff3fd75329e1\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=9a864dc7baab184e9e80ae46a57dc5db3857fd41ab523c0bc905e07888dec3ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/26/e9/df16869ccbd4abf517f1ff3be9a2c7ee5c5980fc87eea04fb1\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n"
          ]
        }
      ],
      "source": [
        "#@title Imports\n",
        "!pip install bert-for-tf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x5Y7kk196uY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973167b7-cd16-4cfb-c3c8-bb9945131678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import bert\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from abc import ABC, abstractmethod # Abstract Base Classes for Python\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from gc import callbacks\n",
        "from pandas import read_csv\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.layers import Embedding,Dense, Input, LSTM, Bidirectional, Dropout\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import  Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import LSTM\n",
        "from keras import layers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWAN7Ob4FP_m"
      },
      "source": [
        "We start by loading our dataset for the ML model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "gAf8ga_l21Qt",
        "outputId": "98f13c70-4e14-4221-ec54-e86575de0a20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           clean_text  is_depression\n",
              "0   we understand that most people who reply immed...              1\n",
              "1   welcome to r depression s check in post a plac...              1\n",
              "2   anyone else instead of sleeping more when depr...              1\n",
              "3   i ve kind of stuffed around a lot in my life d...              1\n",
              "4   sleep is my greatest and most comforting escap...              1\n",
              "5   i m year old turning soon in a few month i liv...              1\n",
              "6   i live alone and despite me being prone to lon...              1\n",
              "7   i m not looking for sympathy just simply to st...              1\n",
              "8   i don t know how to communicate all of my thou...              1\n",
              "9   mom i m sad it hurt in my heart the feeling fa...              1\n",
              "10  i ve been struggling with depression for a lon...              1\n",
              "11  idk how to elaborate on it i just started sudd...              1\n",
              "12  i tried to help his family abandoned him so it...              1\n",
              "13  to me it seems like an empty meaningless phras...              1\n",
              "14  my father committed suicide day before my th b...              1\n",
              "15  i don t think i have the ball to do it but i v...              1\n",
              "16  tw suicide yea so my recent symptom of depress...              1\n",
              "17  got no one to talk to have no one around i ve ...              1\n",
              "18  i m sitting on my bed alone in my dark room sm...              1\n",
              "19  i hate myself so much for being like that when...              1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4217404-b426-4a74-8b41-200517a8d791\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>is_depression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>we understand that most people who reply immed...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>welcome to r depression s check in post a plac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>anyone else instead of sleeping more when depr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i ve kind of stuffed around a lot in my life d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sleep is my greatest and most comforting escap...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i m year old turning soon in a few month i liv...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i live alone and despite me being prone to lon...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i m not looking for sympathy just simply to st...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>i don t know how to communicate all of my thou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>mom i m sad it hurt in my heart the feeling fa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>i ve been struggling with depression for a lon...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>idk how to elaborate on it i just started sudd...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i tried to help his family abandoned him so it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>to me it seems like an empty meaningless phras...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>my father committed suicide day before my th b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>i don t think i have the ball to do it but i v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>tw suicide yea so my recent symptom of depress...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>got no one to talk to have no one around i ve ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>i m sitting on my bed alone in my dark room sm...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>i hate myself so much for being like that when...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4217404-b426-4a74-8b41-200517a8d791')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4217404-b426-4a74-8b41-200517a8d791 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4217404-b426-4a74-8b41-200517a8d791');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df=read_csv(\"sample_data/depression_dataset_reddit_cleaned.csv\" )\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkPVTpAo8Vs5"
      },
      "source": [
        "Before we preprocess our dataset and prepare it for the training, let's have a look at the distribution of the labelled data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW4KCyA28gMK",
        "outputId": "fae8361e-acb9-441c-e882-eee31ace44b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3900\n",
              "1    3831\n",
              "Name: is_depression, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df[\"is_depression\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLMsoh-J8qPV"
      },
      "source": [
        "As we can see in the line above, our labels are almost 50% - 50%. Therefore, the dataset is not imbalanced. \n",
        "\n",
        "Next, we will take a look at the average word count of our input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLdhtw8W9CoJ",
        "outputId": "13c1d4ba-229a-42e8-cbb9-606e611b61e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The average word count of the depression input is 136 words\n",
            "The average word count of the nondepression input is 14 words\n"
          ]
        }
      ],
      "source": [
        "df_depression = df[df['is_depression'] == 1]\n",
        "df_non_depression = df[df['is_depression'] == 0]\n",
        "\n",
        "depression_avg_word_count = int(df_depression['clean_text'].str.split(\" \").apply(len).mean())\n",
        "nondepression_avg_word_count = int(df_non_depression['clean_text'].str.split(\" \").apply(len).mean())\n",
        "\n",
        "print(f\"The average word count of the depression input is {depression_avg_word_count} words\")\n",
        "print(f\"The average word count of the nondepression input is {nondepression_avg_word_count} words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split our dataset in two different ways for convenience. For LSTM, we will split it in the following code block and use later on"
      ],
      "metadata": {
        "id": "yJxWGLCYo-9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uJmAR8n8IEhu"
      },
      "outputs": [],
      "source": [
        "X,Y = df[\"clean_text\"], df[\"is_depression\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y ,test_size=0.2, random_state = 235, stratify=Y )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCE8VE7iELaY"
      },
      "source": [
        "For BERT, we will first encode our data with the Universal Sentence Encoder and then split the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "X_encoded = np.array(bert_encoder(X))\n",
        "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(X_encoded, Y , test_size=0.2, random_state = 235, stratify=Y)"
      ],
      "metadata": {
        "id": "MgBS1pG3FlzC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define our base class algorithm to inherit later on."
      ],
      "metadata": {
        "id": "gMQjMoSWpJmI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iD9quIFA21cq"
      },
      "outputs": [],
      "source": [
        "#@title Base Class for Learning Algorithm\n",
        "\n",
        "class BaseLearningAlgorithm(ABC):\n",
        "  \"\"\"Base class for a Supervised Learning Algorithm.\"\"\"\n",
        "\n",
        "  @abstractmethod\n",
        "  def fit(self, X_train:np.array, y_train: np.array) -> None:\n",
        "    \"\"\"Trains a model from labels y and examples X.\n",
        "    We include validation set for optional hyperparameter tuning. Not \n",
        "    all of the algorithims we use will    \n",
        "    \"\"\"\n",
        "\n",
        "  @abstractmethod\n",
        "  def predict(self, X_test: np.array) -> np.array:\n",
        "    \"\"\"Predicts on an unlabeled sample, X.\"\"\"\n",
        "\n",
        "  @property\n",
        "  @abstractmethod\n",
        "  def name(self) -> str:\n",
        "    \"\"\"Returns the name of the algorithm.\"\"\"\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEJwHjOq5yP9"
      },
      "source": [
        "Let's define our BERTClassifier class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "__mcShfJBvpP"
      },
      "outputs": [],
      "source": [
        "#@title 1 - BERT Model\n",
        "class BERTClassifier(BaseLearningAlgorithm):\n",
        "  def __init__(self):\n",
        "    text_input = Input(shape=(512,), name='text')\n",
        "    l = Dense(2048, activation = \"relu\")(text_input)\n",
        "    l = Dense(1024, activation = \"relu\")(l)\n",
        "    l = Dropout(0.1, name=\"dropout\")(l)\n",
        "    l = Dense(512, activation = \"relu\")(l)\n",
        "    l = Dense(256, activation = \"relu\")(l)\n",
        "    l = Dropout(0.1, name=\"dropout2\")(l)\n",
        "    l = Dense(128, activation = \"relu\")(l)\n",
        "    l = Dense(64, activation = \"relu\")(l)\n",
        "    l = Dense(1, activation='sigmoid', name=\"output\")(l)\n",
        "    self.model = Model(inputs=[text_input], outputs = [l])\n",
        "    self.model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate= 0.00001), metrics = [\"accuracy\"])\n",
        "\n",
        "  def fit(self, X_train:np.array, y_train: np.array , epochs, validation_split):\n",
        "    self.model.fit(X_train, y_train, epochs=epochs, validation_split=validation_split, \n",
        "                   callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode=\"min\")])\n",
        "\n",
        "  def predict(self, X_test, threshold=0.3) -> np.array:\n",
        "    predictions = self.model.predict(X_test)\n",
        "    binary_predictions = [1 if prediction > threshold else 0 for prediction in predictions]\n",
        "    return binary_predictions\n",
        "  \n",
        "  def summary(self):\n",
        "    self.model.summary()\n",
        "\n",
        "\n",
        "  @property \n",
        "  def name(self) -> str:\n",
        "    \"\"\"Returns the name of the algorithm.\"\"\"\n",
        "    return \"BERT model\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have defined our BERTClassifier above and now it is time to initialize, train and evaluate it! Simply run the following driver code block."
      ],
      "metadata": {
        "id": "1mec9681pt_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a_5XZYCJB6DZ",
        "outputId": "a1ee9f96-d3e1-40d0-99e8-816cd373043c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "136/136 [==============================] - 1s 5ms/step - loss: 0.6705 - accuracy: 0.6717 - val_loss: 0.6164 - val_accuracy: 0.8971\n",
            "Epoch 2/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.4775 - accuracy: 0.9140 - val_loss: 0.2836 - val_accuracy: 0.9564\n",
            "Epoch 3/10\n",
            "136/136 [==============================] - 1s 5ms/step - loss: 0.1835 - accuracy: 0.9630 - val_loss: 0.1059 - val_accuracy: 0.9731\n",
            "Epoch 4/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9670 - val_loss: 0.0801 - val_accuracy: 0.9768\n",
            "Epoch 5/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.0834 - accuracy: 0.9716 - val_loss: 0.0744 - val_accuracy: 0.9731\n",
            "Epoch 6/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.0726 - accuracy: 0.9755 - val_loss: 0.0681 - val_accuracy: 0.9747\n",
            "Epoch 7/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9771 - val_loss: 0.0660 - val_accuracy: 0.9763\n",
            "Epoch 8/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.0602 - accuracy: 0.9794 - val_loss: 0.0640 - val_accuracy: 0.9784\n",
            "Epoch 9/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.0529 - accuracy: 0.9808 - val_loss: 0.0641 - val_accuracy: 0.9774\n",
            "Epoch 10/10\n",
            "136/136 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9836 - val_loss: 0.0646 - val_accuracy: 0.9758\n",
            "49/49 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       780\n",
            "           1       0.97      0.98      0.97       767\n",
            "\n",
            "    accuracy                           0.97      1547\n",
            "   macro avg       0.97      0.97      0.97      1547\n",
            "weighted avg       0.97      0.97      0.97      1547\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert = BERTClassifier()\n",
        "bert.fit(X_train_encoded, y_train_encoded, epochs = 10, validation_split=0.3)\n",
        "yhats = bert.predict(X_test_encoded)\n",
        "mat = confusion_matrix(y_test, yhats)\n",
        "sns.set(rc = {'figure.figsize':(8,8)})\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "              xticklabels=['%d' %i for i in range(2)],\n",
        "              yticklabels=['%d' %i for i in range(2)])\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n",
        "plt.title('Bert Model')\n",
        "  \n",
        "print(classification_report(y_test, yhats,\n",
        "                              target_names=['%d' %i for i in range(2)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is done! The results already look great even with 10 epochs. However, since this is a some sort of sentiment detection model, our priority should be minimizing the false negatives. To do this, we might sacrifice a tiny bit of accuracy. We will simply lower the threshold in the code block below and see how our model performs... We will set the threshold to 2 and see recall values."
      ],
      "metadata": {
        "id": "4HBLJc7ZqA04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, it looks like we found the sweet spot. We not only reduced the recall, but also kept the precision and accuracy high!\n",
        "\n",
        "Now let's add some sample sentences to see how the model performs in real world scenarios"
      ],
      "metadata": {
        "id": "aLQhNIeJq_4b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZn_wTws8uyG",
        "outputId": "f74446d7-d589-453a-8431-b9ff2f55b402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "[1, 0, 0, 1, 1, 0, 1, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "sample = [\n",
        "    \"i wanna die so bad that i might kill myself tomorrow\",\n",
        "    \"i love it when it snows\",\n",
        "    \"i went to a fast food today and ate burgers\",\n",
        "    \"today was the day where i almost ended it all i have been thinking of comitting suicide for months\",\n",
        "    \"life is so bad man i dont know i feel terrible\",\n",
        "    \"i m feeling tired today\",\n",
        "    \"i am so done bro\",\n",
        "    \"i want to go to sleep and wake up early tomorrow\",\n",
        "    \"i am so stressed about my exam tomorrow i need help so badly depressed\",\n",
        "    \"i am feeling so lonely\",\n",
        "    ]\n",
        "sample_encoded = np.array(bert_encoder(sample))\n",
        "print(bert.predict(sample_encoded, threshold = 0.3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Gut0Vr60PMlM"
      },
      "outputs": [],
      "source": [
        "#@title 2 - LSTM Model\n",
        "class LSTMClassifier(BaseLearningAlgorithm):\n",
        "  def __init__(self):\n",
        "    self.vocab_size = 20000\n",
        "    self.embedding_dim = 1024\n",
        "    self.tokenizer = Tokenizer(num_words = 20000)\n",
        "    self.model = Sequential([\n",
        "        Embedding(self.vocab_size, self.embedding_dim, input_length = 1024),\n",
        "        Bidirectional(LSTM(1024)),\n",
        "        Dense(2048, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(2048, activation='relu'),\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    self.model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate= 0.00001), metrics = [\"accuracy\"])\n",
        "\n",
        "  def fit(self, X_train:np.array, y_train: np.array , epochs, validation_split):\n",
        "    self.tokenizer.fit_on_texts(X_train)\n",
        "    X_train_sequences = self.tokenizer.texts_to_sequences(X_train)\n",
        "    X_train_tokenized = pad_sequences(X_train_sequences,truncating=\"post\",padding=\"post\", maxlen=1024, dtype='float32')\n",
        "    self.model.fit(X_train_tokenized, y_train, validation_split= validation_split, epochs=epochs, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode=\"min\")])\n",
        "\n",
        "  def predict(self, X_test, threshold) -> np.array:\n",
        "    self.tokenizer.fit_on_texts(X_test)\n",
        "    X_test_sequences = self.tokenizer.texts_to_sequences(X_test)\n",
        "    X_test_tokenized = pad_sequences(X_test_sequences,truncating=\"post\",padding=\"post\", maxlen=1024, dtype='float32') \n",
        "    predictions = self.model.predict(X_test_tokenized)\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    scaler.fit(predictions)\n",
        "    normalized_predictions = scaler.transform(predictions)\n",
        "    binary_predictions = [1 if prediction > threshold else 0 for prediction in normalized_predictions ]\n",
        "    return [normalized_predictions, binary_predictions]\n",
        "\n",
        "  \n",
        "  def summary(self):\n",
        "    self.model.summary()\n",
        "\n",
        "\n",
        "  @property \n",
        "  def name(self) -> str:\n",
        "    \"\"\"Returns the name of the algorithm.\"\"\"\n",
        "    return \"LSTM model\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's instantiate our class, train and evaluate it..."
      ],
      "metadata": {
        "id": "pAYZT6qHs3He"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDzvMF1Qx5jk",
        "outputId": "a77ea1c1-7f38-4bda-e07b-89743551fbc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "155/155 [==============================] - 35s 187ms/step - loss: 0.5713 - accuracy: 0.7109 - val_loss: 0.3325 - val_accuracy: 0.8860\n",
            "Epoch 2/100\n",
            " 75/155 [=============>................] - ETA: 13s - loss: 0.3477 - accuracy: 0.8667"
          ]
        }
      ],
      "source": [
        "lstm = LSTMClassifier()\n",
        "lstm.fit(X_train, y_train, epochs = 100, validation_split=0.2)\n",
        "yhats = lstm.predict(X_test, threshold = 0.5)\n",
        "mat = confusion_matrix(y_test, yhats)\n",
        "sns.set(rc = {'figure.figsize':(8,8)})\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "              xticklabels=['%d' %i for i in range(2)],\n",
        "              yticklabels=['%d' %i for i in range(2)])\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')\n",
        "plt.title('Bert Model')\n",
        "  \n",
        "print(classification_report(y_test, yhats,\n",
        "                              target_names=['%d' %i for i in range(2)]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhats = lstm.predict(X_test, threshold = 0.1)\n",
        "print(classification_report(y_test, yhats[1]))\n",
        "confusion_matrix(y_test,yhats[1]) #yhats[1] returns binary predictions we made (0 or 1) "
      ],
      "metadata": {
        "id": "s4FKLDPAAS3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it can be seen, the LSTM model doesn't perform as good as our BERT model.While changing the classification threshold helps a bit, it is still not as good as BERT."
      ],
      "metadata": {
        "id": "t97wrAqwtOhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's save the trained models using pickle module to use at a later time or deploy!"
      ],
      "metadata": {
        "id": "3FUGnsXotcyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(bert, open(\"bert.pickle\", \"wb\"))\n",
        "pickle.dump(lstm, open(\"lstm.pickle\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs90ebFxZn4b",
        "outputId": "2413401f-7700-4ed2-e3ff-40e191d9b3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_fn, lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(bert, open(\"bert\", \"wb\"))\n"
      ],
      "metadata": {
        "id": "qUXfq2McGJZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM9d6qAkBc9Z"
      },
      "source": [
        "DONE!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}